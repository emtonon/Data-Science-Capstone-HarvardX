---
title: "Movie Recommendation System"
subtitle: "HarvardX Data Science PH125.9x Capstone - MovieLens"
author: "Erik Martins Tonon"
date: "September 2022"
output: pdf_document
number_sections: true
toc: true
bibliography: references.bib
---


```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")

#################### Packages #################### 
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(knitr)) install.packages("knitr")
if(!require(kableExtra)) install.packages("kableExtra")
if(!require(dplyr)) install.packages("dplyr")

```


```{r include=FALSE, cache = TRUE}

library(tidyverse)
library(caret)
library(data.table)
library(ggplot2)
library(knitr)
library(kableExtra)
library(dplyr)

#################### Data Sets #################### 
# Create edx set, validation set (final hold-out test set)
# Note: this process could take a couple of minutes

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/  
# http://files.grouplens.org/datasets/movielens/ml-10m.zip  

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
#                                           title = as.character(title),
#                                           genres = as.character(genres))

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

#################### edX / Validation #################### 
# Validation set will be 10% of MovieLens data
set.seed(1) # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
# Cleaning up memory
gc()

#################### Functions #################### 
#Converting Epoch date to Human Date
to_date <- function(x) {
  as.Date(as.POSIXct(x, origin="1970-01-01"))
}

get_year <- function(x) {
  format(as.Date(as.POSIXct(x, origin="1970-01-01")),"%Y")
}

#################### Data set Mutation #################### 

#Split train & test set by randomly selecting 10% of the **edx set**

set.seed(1)
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
train_set <- edx[-test_index,]
temp <- edx[test_index,]

# Make sure userId and movieId in test set are also in train set
test_set <- temp %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Add rows removed from test set back into train set
removed <- anti_join(temp, test_set)
train_set <- rbind(train_set, removed)

rm(test_index, temp, removed)

##  Review Year mutation
train_set <- train_set %>%
  mutate(review_year = get_year(timestamp))

test_set <- test_set %>%
  mutate(review_year = get_year(timestamp))

##  Review Year and Title Year mutation (edx vs validation)
edx <- edx %>%
  mutate(review_year = get_year(timestamp))

validation <- validation %>%
  mutate(review_year = get_year(timestamp))

```

\newpage

## Introduction

Machine learning is an evolving branch of computational algorithms that are designed to emulate human intelligence by learning from the surrounding environment (@ElNaqa2015).

Recommendation systems have become prevalent in recent years as they deal with the information overload problem by suggesting to users the most relevant products from a massive amount of data (@WANG2014667).

With over 10 million ratings and more than 10 thousand unique movies, the MovieLens dataset (@harper_2015) will be used in this project to create a movie recommendation system using Machine Learning.
 
The users were selected at random for inclusion and each user is represented by an id, and no other information was provided. The dataset contains not only ratings but movie genres, titles and the date when the review was submitted.
 
The goal of this project is to predict movie ratings based on the MovieLens dataset. To achieve this, the information collected from this dataset will be divided into two other datasets: the train dataset *(edx)* and the validation *(validation)* dataset, which consists of 10% of the original dataset and will not be used along the development of the recommendation system, only at the final hold-out test.

The objective is to predict ratings with a Root Mean Square Error *(RMSE)* less than **0.86490** against the ratings in the validation set.

The RMSE is defined as :

$$\mbox{RMSE} = \sqrt{\frac{1}{N} \sum_{u,i}^{} \left( \hat{y}_{u,i} - y_{u,i} \right)^2}$$
\newpage

## Exploratory Analysis

The dataset *‘edx’* contains precisely 9.000.055 rows, 6 variables, ratings provided by 69.878 unique users and 10.677 unique movies.

A simple analysis already tells us that not every user had rated a movie, otherwise, we would have more than 746 million ratings.


``` {r out.width = "60%", echo = FALSE}
first10 <-head(edx, 10) %>%
  select(userId, movieId,rating,timestamp,title,genres)

knitr::kable(first10, caption="First 10 rows of edx dataset.", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position", "scale_down"),
                position = "center")

```

### Users

Taking a closer look at "$userId", it is possible to identify some patterns of ratings in which some users have rated more movies than others (Figure 1).

It indicates that some users are more active than others which could suggest a potential user bias. This study could help improve the accuracy of the algorithm.

``` {r out.width = "60%", fig.cap="Ratings per User", echo = FALSE}

hist_users <- edx %>%
  count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram( bins=25, color = I("black"), fill = "darkseagreen4") +
  scale_x_log10() +
  labs(x = "Users", 
       y = "Number of ratings") 
       
hist_users
```


\newpage

### Movies

The analysis of the movie data collected demonstrates significant variation in the number of ratings per movie (Figure 2). Some movies received higher ratings than others (Figure 3), stating that there is a movie effect on the rating, which can potentially improve our training algorithm.
``` {r out.width = "60%", fig.cap="Ratings per Movie", echo = FALSE}
hist_movies <- edx %>%
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram( bins=25, color = I("black"), fill = "darkseagreen4") +
  scale_x_log10() +
  labs(x = "Movies", 
       y = "Number of ratings") 

hist_movies
```
``` {r out.width = "60%", fig.cap="Average rating per Movie", echo = FALSE}

avg_movies <- edx %>% 
  group_by(movieId) %>%
  summarise(avg = sum(rating/n())) %>%
  ggplot(aes(avg)) +
  geom_histogram( bins=25, color = I("black"), fill = "darkseagreen4") +
  labs(x = "Average Rating", 
       y = "Number of Movies") 

avg_movies
```

\newpage

### Movie Genres
As seen in Table 1, the genres have been treated together *(“Drama|Comedy|Romance”)*, and a movie can be tagged with more than one genre.

*"Drama"*, for instance, had the most rating (Table 2), while Documentary and IMAX (Table 3) had the fewest. 

We can see that 6 ratings were provided for movies without genre.

``` {r out.width = "60%", echo = FALSE}

movie_genres <- edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarise(count = n(), rating = round(mean(rating), 2)) %>%
  arrange(desc(count))


knitr::kable(head(movie_genres,3), caption="Most Rated", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")


knitr::kable(tail(movie_genres,3), caption="Least Rated", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

Among the highest rates, *‘Film-Noir’* has an average of 4.01 whereas *‘Western’* has 3.56 (Table 4).

``` {r out.width = "60%", echo = FALSE}

high_rates <- movie_genres %>%
  arrange(desc(rating)) %>% head(.,10)

knitr::kable(high_rates, caption="Highest rates", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")


``` 

\newpage

### Movie Title

As seen before, the variable *‘$Title’* contains both the name of the movie and the year of release. We see the top 10 most-rated movies topped by *‘Pulp Fiction (1994)’* as the most rated movie (Table 5).

``` {r out.width = "60%", echo = FALSE}

top_10_rated <- edx %>% 
  group_by(title) %>%
  summarise(n = n()) %>%
  slice_max(n, n=10)

knitr::kable(top_10_rated, caption = "Top 10 Most Rated Movies", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

``` 

### Rating

We can also observe in the distribution of ratings (Figure 4) that 4 star ratings out of 5 were the most frequent and that half-integers stars were less frequent.

```{r out.width = "60%", fig.cap="Histogram of ratings per movie", echo = FALSE}

hist_rating <- edx %>%
  ggplot(aes(rating)) +
  geom_histogram( bins=25, color = I("black"), fill = "darkseagreen4") +
  labs(
    x = "Ratings", y = "Count", fill = element_blank()
  )

hist_rating 
```

### Review Date

The dataset was provided with a review date *($timestamp)* recorded when the rating was submitted. However, the variable needs to be transformed into human-readable information once it is in Epoch format.

We can observe that the earliest review was in 1995 while the Year 2000 has the highest amount of reviews. (Figure 5)

```{r out.width = "60%", fig.cap="Number of ratings per Year", echo = FALSE}

hist_date_review <- edx %>% 
  ggplot(aes(get_year(timestamp))) +
  geom_bar(color = I("black"), fill = "darkseagreen4") +
  labs(
    x = "Year", y = "Count", fill = element_blank()
  )

hist_date_review


rm(hist_date_review, hist_movies,hist_rating,hist_users, movie_genres) 
```

\newpage

## Methods

We can interpret the RMSE similarly to a standard deviation: it is the typical error we make when predicting a movie rating. If this number is larger than 1, it means our typical error is larger than one star, which is not good. (@irizarry_2020)

### Naive Recommendation

Due to the large size of the dataset, it will not be possible to fit the model using the *lm()* function as it can be very slow using normal computers, then we will calculate it manually.

The naive model is the most simple and it predicts that the movies will have the same rating regardless of user, genre or movie and the estimate that minimizes the RMSE is the average of all ratings. 

We can define a model that assumes the same rating for all movies and users and for this model we have: $$Y_{u,i}=\mu+\epsilon_{u,i}$$ 
```{r out.width = "60%", echo = FALSE}

rmse_results <- data.frame(Method = "Objective", RMSE = "0.86490")


knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

Calculate the overall average rating across all movies included in train set and calculate RMSE between each rating included in test set and the overall average.

```{r out.width = "60%", echo=FALSE }
mu_hat <- mean(train_set$rating)

naive_rmse <- round(RMSE(train_set$rating, mu_hat),5)

rmse_results <- rmse_results %>%
  rbind(c("Simple Average", naive_rmse))

knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")
```

### Movie Effect (b_i)

As we have seen before, some movies have a higher number of ratings than others, therefore we can improve our model by adding the movie effect ($b_i$).
$$Y_{u,i} = \mu + b_i + \varepsilon_{u,i}$$ 

```{r echo=TRUE }
#Dropping hat to represent estimates
mu <- mean(train_set$rating)

b_i <- train_set %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu))
```

Predict ratings adjusting for movie effects
```{r echo=TRUE }
pred_ratings <- mu + test_set %>%
  left_join(b_i, by = "movieId") %>%
  pull(b_i)
```
Calculate RMSE based on movie effects model
```{r echo=TRUE }
b_i_rmse <- format(round(RMSE(pred_ratings, test_set$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Movie Effect (b_i)", b_i_rmse))
```

We can see an improvement to the model as shown in the RMSE below:

```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```
### Movie, User effect (b_u)
We can also see the same bias by users ($b_u$), where some users rate less than others.
$$Y_{u,i} = \mu + b_i + b_u + \varepsilon_{u,i}$$ 

```{r echo=TRUE }
b_u <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

pred_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

b_u_rmse <- format(round(RMSE(pred_ratings, test_set$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Movie + User Effect (b_u)", b_u_rmse))
```

Adding users ($b_u$) to the algorithm has greatly improved the model, as suspected in the initial analysis.

```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```
### Movie, Users and Genre Effect (b_g)

As we have seen in the data exploration, the movie genres $(b_g)$ are treated together for each movie. Let’s evaluate them using the following formula:
$$Y_{u,i} = \mu + b_i + b_u + b_g + \varepsilon_{u,i}$$ 

```{r echo=TRUE }
b_g <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  group_by(genres) %>%
  summarize(b_g = mean(rating - mu - b_i - b_u))

pred_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = c("genres")) %>%
  mutate(pred = mu + b_i  + b_u + b_g) %>%
  pull(pred)

b_g_rmse <- format(round(RMSE(pred_ratings, test_set$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Movie + User + Genre Effect (b_g)", b_g_rmse))
```

Adding genres $(b_g)$ to the model has not improved the algorithm much.

```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

### Movie, Users, Genre  + Review Year Effect (b_y)

The dataset provides us information in Epoch format for when the review $(b_y)$ was submitted and we can improve our model with the following formula:
$$Y_{u,i} = \mu + b_i + b_u + b_g + b_y +  \varepsilon_{u,i}$$ 

```{r echo=TRUE }
b_y <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = "genres" ) %>%
  group_by(review_year) %>%
  summarize(b_y = mean(rating - mu - b_i - b_u - b_g))

pred_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = "genres") %>%
  left_join(b_y, by = "review_year") %>%
  mutate(pred = mu + b_i  + b_u + b_g + b_y) %>%
  pull(pred)

b_y_rmse <- format(round(RMSE(pred_ratings, test_set$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Movie + Users + Genre + Review Year Effect (b_y)", b_y_rmse))
```



Adding the Review Year $(b_y)$ to the model has slightly improved the algorithm, but we can achieve better results by adding regularization.


```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

\newpage

### Regularization

To make better estimates, we have to penalize cases where movies were rated by fewer users. Otherwise, we will have noisy estimates. The general idea behind regularization is to constrain the total variability of the effect sizes. (@irizarry_2020)

$$ \sum_{u,i} \left(y_{u,i} - \mu - b_i - b_u - b_g - b_y \right)^2 +
\lambda \left(\sum_{i} b_i^2 + \sum_{u} b_u^2 + \sum_{g} b_g^2 + \sum_{y} b_y^2\right) $$

```{r echo=FALSE }

lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  
  mu <- mean(train_set$rating)
  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  
  b_u <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - mu - b_i)/(n()+l))
  
  b_g <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = 'userId' ) %>%
    group_by(genres) %>%
    summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+l))
  
  b_y <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = 'userId' ) %>%
    left_join(b_g, by = "genres" ) %>%
    group_by(review_year) %>%
    summarize(b_y = sum(rating - mu - b_i - b_u - b_g)/(n()+l))
  
  pred_ratings <- 
    test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId" ) %>%
    left_join(b_g, by = "genres" ) %>% 
    left_join(b_y, by = "review_year") %>%
    mutate(pred = mu + b_i + b_u + b_g + b_y) %>%
    pull(pred)
  
  return(RMSE(pred_ratings, test_set$rating))
})

```

Below at Figure 6, the value for $\lambda$ that obtains the minimum RMSE for our model is 5.25.

```{r out.width = "60%", fig.cap = "Minimum Lambda per RMSE",  echo=FALSE }
qplot(lambdas, rmses) 
```
```{r echo=FALSE }
lambda <- lambdas[which.min(rmses)]
knitr::kable(lambda, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

Applying the most optimized $\lambda$ to the model.

```{r echo=TRUE }

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu - b_i)/(n()+lambda))

b_g <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId" ) %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+lambda))

b_y <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId" ) %>%
  left_join(b_g, by = "genres" ) %>%
  group_by(review_year) %>%
  summarize(b_y = sum(rating - mu - b_i - b_u - b_g)/(n()+lambda))

pred_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = "genres" ) %>%
  left_join(b_y, by = "review_year") %>%
  mutate(pred = mu + b_i + b_u + b_g + b_y) %>%
  pull(pred)

reg_rmse <- format(round(RMSE(pred_ratings, test_set$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Regularized Movie + User + Genre + Year Effect", reg_rmse))
```

By performing full-cross validation with Regularized Movie + User + Genre + Year has greatly improved the model:

```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```
\newpage
# Results

The model that combined the regularized Movie + User + Genre + Year Effect had the best results using the train and test data set, achieving the RMSE goal.

For the final validation, the model should be tested with the *validation* dataset.


```{r echo=TRUE }
mu <- mean(edx$rating)

b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- edx %>%
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu - b_i)/(n()+lambda))

b_g <- edx %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId" ) %>%
  group_by(genres) %>%
  summarize(b_g = sum(rating - mu - b_i - b_u)/(n()+lambda))

b_y <- edx %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId" ) %>%
  left_join(b_g, by = "genres" ) %>%
  group_by(review_year) %>%
  summarize(b_y = sum(rating - mu - b_i - b_u - b_g)/(n()+lambda))

pred_ratings <- validation %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = "genres" ) %>%
  left_join(b_y, by = "review_year") %>%
  mutate(pred = mu + b_i + b_u + b_g + b_y) %>%
  pull(pred)

reg_rmse <- format(round(RMSE(pred_ratings, validation$rating),5), nsmall = 5)

rmse_results <- rmse_results %>%
  rbind(c("Final Validation", reg_rmse))
```

Finally, we evaluate the final hold-out test with the RMSE below the target.

```{r out.width = "60%", echo=FALSE }
knitr::kable(rmse_results, 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")

```

The achieved RMSE 0.86463 with the *validation* data set is below the target and thus, enough for the project expectation. 


```{r echo=FALSE}
top_10_validation <- validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = 'userId' ) %>%
  left_join(b_g, by = "genres" ) %>%
  left_join(b_y, by = "review_year") %>%
  mutate(pred = mu + b_i + b_u + b_g + b_y) %>% 
  arrange(-pred) %>% 
  group_by(title) %>% 
  select(title) %>%
  head(10)


knitr::kable(top_10_validation, caption = "Top 10 Most Rated Movies - Validation data set", 
               booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "HOLD_position"),
                position = "center")
```

# Conclusion

Given the size of the data set and the few variables available, it was possible to achieve the RMSE target by using the Regularized Movie, User, Genre and Review Year model. We explored the data set and identified some patterns around ‘Users’ and ‘Movies’ that could improve our algorithm. 

The naive recommendation provided the worst result since it is the simple average regardless of user or movie. Afterwards, we saw that combining Movie and User in our algorithm had made a huge impact of around 18% compared to the simple average.

Finally by adding penalty to the model with regularization, it achieved the RMSE of **0.86364** with the test set and **0.86463** with the final validation with the validation data set - both below the target RMSE **0.86490**.

Having further user information, such as age, location and gender for instance, would have enriched this research.

\newpage
# References

